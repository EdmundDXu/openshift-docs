// Module included in the following assemblies:
//
// * nodes/nodes-scheduler-default.adoc

[id="nodes-scheduler-default-modifying_{context}"]
= Modifying scheduler policies

//Made changes to this file to match https://github.com/openshift/openshift-docs/pull/13626/files#diff-ba6ab177a3e2867eaefe07f48bd6e158

You change scheduling behavior by creating or editing your scheduler policy ConfigMap in the `openshift-config` project.
Add and remove predicates and priorities to the ConfigMap to create a _scheduler policy_.

.Typical predicate string
----
\n\t{\"name\" : \"<PredicateName>\", \"label\" : \"<label>\",  \"<condition>\" : \"<state>\"},
----
* `name` is the name of the predicate, such as `labelsPresence`. 
* `label` and `<label>` is the node label:value pair to match to apply the predicate, such `label:rack`.
* `<condition>` and `<state>` is when the predicate should be applied, such as `presence:true`.

.Typical priority string
----
\n\t{\"name\" : \"<PredicateName>\", \"label\" : \"<label>\",  \"<condition>\" : \"<state>\", \"weight\" : <weight>},
----
* `name` is the name of the priority, such as `labelsPresence`. 
* `label` and `<label>` is the node `label:value` pair to match to apply the priority, such `label:rack`.
* `<condition>` and `<state>` is when the priority should be applied, such as `presence:true`.
* `weight` and `<weight> is the numerical weight to apply to the priority.

.Procedure

To modify the scheduler policy:

Edit the scheduler configuration file to configure the desired
predicates and priorities. 

.Sample modified scheduler configuration map
[source,yaml]
----
kind: ConfigMap
apiVersion: v1
metadata:
  name: scheduler-policy
  namespace: openshift-config
  selfLink: /api/v1/namespaces/openshift-config/configmaps/mypolicy
  uid: 83917dfb-4422-11e9-b2c9-0a5e37b2b12e
  resourceVersion: '1049773'
  creationTimestamp: '2019-03-11T17:24:23Z'
data:
  policy.cfg: "{\n\"kind\" : \"Policy\",\n\"apiVersion\" : \"v1\",\n\"predicates\" : [\n\t{\"name\" : \"PodFitsHostPorts\"},\n\t{\"name\" : \"PodFitsResources\"},\n\t{\"name\" : \"NoDiskConflict\"},\n\t{\"name\" : \"NoVolumeZoneConflict\"},\n\t{\"name\" : \"MatchNodeSelector\"},\n\t{\"name\" : \"HostName\"}\n\t],\n\"priorities\" : [\n\t{\"name\" : \"LeastRequestedPriority\", \"weight\" : 10},\n\t{\"name\" : \"BalancedResourceAllocation\", \"weight\" : 1},\n\t{\"name\" : \"ServiceSpreadingPriority\", \"weight\" : 1},\n\t{\"name\" : \"EqualPriority\", \"weight\" : 1}\n\t]\n}\n"
----

For example, the following strings add the `labelpresence` predicate requiring the `rack` label on the nodes and the `labelPreference` priority giving a weight of 2 to the `rack` label:

[source,yaml]
----
\n\t{\"name\" : \"labelPresence\", \"label\" : \"rack\",  \"presence\" : \"true\"},
\n\t{\"name\" : \"labelPreference\", \"label\" : \"rack\", \"presence\" : \"true\", \"weight\" : 2},\n\t
----

The ConfigMap appears as following with the new priority:

[source,yaml]
----
policy.cfg: "{\n\"kind\" : \"Policy\",\n\"apiVersion\" : \"v1\",\n\"predicates\" : [\n\t{\"name\" : \"PodFitsHostPorts\"},\n\t{\"name\" : \"PodFitsResources\"},\n\t{\"name\" : \"NoDiskConflict\"},\n\t{\"name\" : \"NoVolumeZoneConflict\"},\n\t{\"name\" : \"MatchNodeSelector\"},\n\t{\"name\" : \"HostName\"},\n\t{\"name\" : \"labelPresence\", \"label\" : \"rack\",  \"presence\" : \"true\"}\n\t],\n\"priorities\" : [\n\t{\"name\" : \"LeastRequestedPriority\", \"weight\" : 10},\n\t{\"name\" : \"BalancedResourceAllocation\", \"weight\" : 1},\n\t{\"name\" : \"ServiceSpreadingPriority\", \"weight\" : 1},\n\t{\"name\" : \"EqualPriority\", \"weight\" : 1},\n\t{\"name\" : \"labelPreference\", \"label\" : \"rack\", \"presence\" : \"true\", \"weight\" : 2},\n\t]\n}\n "
----
